<!DOCTYPE HTML>
<!--
	Introspect by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>Implementation - IntelliChirp</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body>

		<!-- Header -->
		<header id="header">
			<div class="inner" style="text-align: center">
				<nav id="nav">
					<a href="index.html">Home</a>
					<a href="team.html">Team</a>
					<a href="implementation.html">Implementation</a>
                    <a href="documents.html">Documents</a>
                    <a href="schedule.html">Schedule</a>
					<a href="https://soundscapes2landscapes.org/">Visit Sponsors</a>
				</nav>
			</div>
		</header>
		<a href="#menu" class="navPanelToggle"><span class="fa fa-bars"></span></a>

		<!-- Main -->
			<section id="main" >
				<div class="inner">
					<header>
						<h2>Project Description</h2>
					</header>
					<p>
						Various environmental changes affect a range of species around the world and as more
						species are being affected, proper management and observation are required to understand their response.
						Traditional field methods require trained observers to determine species presence/absence and are thus
						expensive and challenging to employ at large scales. Using sound to monitor biodiversity 
						across landscapes is a fairly recent development.
						<br/><br/>
						Our clients are working with
						<a href="https://soundscapes2landscapes.org/">
							Soundscapes2Landscapes.
						</a>
						They are having a problem with an un-user friendly application that requires manual identification in terabytes of sound files. This manual approach is incredibly time consuming
						and needs to be automated. We feel confident that we can provide 
						a solution that is user friendly and automates that identification process with machine learning.
						<br/><br/>The initial concept for this project was provided by our sponsor, in the form of a 
						<a href="https://www.cefns.nau.edu/~edo/Classes/CS_Capstone/Projects/F19/Quinn-Burns-Soundscapes2.pdf">
							Capstone Proposal.
						</a>
					</p>
				</div>
			</section>

			<section id="main">
				<div class="inner">
					<header>
						<h2>High Level Requirements</h2>
					</header>
					<p>
						<ul>
  							<li>
  								Users will be able to upload audio files.
							</li>
  							<li>
  								Users will be able to analyze all uploaded audio files.
							</li>
  							<li>
  								Users will be able to see the results of the analysis visualized.
  							</li>
   							<li>
  								Users will be able to receive the results of the analysis in a timely manner.
  							</li>							
  							<li>
  								Users will be able to export all results.
  							</li>
						</ul>
						The development process included weekly meetings with our clients. We have iteratively refined our requirements
						in each of these meetings. Under the Documents tab, there is a link to our requirements document.
					</p>
				</div>
			</section>

			<section id="main">
				<div class="inner">
					<header class="major special">
						<h2>Envisioned Solution</h2>
					</header>
					<p>
						Our envisioned solution is a user friendly web application for use by any researcher or citizen scientist.
						This application is called the <b>Soundscape Noise Analysis Workbench (S.N.A.W.)</b>, and will allow 
						users to analyze sound files with the power of machine learning. 
						The results given to the users include a summary of the audio components in the file,
  						acoustic indices, and an export of the sound file with background noise masked out. Users will gain a better 
						understanding of how various sources of noise in soundscape recordings diminish the ability to detect 
						individual bird species and quantify avian diversity. Using machine learning, instead of
						the current manual identification process, will drastically speed up the identification of terabytes of 
						acoustic data. This solution will allow users anywhere, anytime, to upload their soundscapes for noise analysis, quickly.
					</p>
				</div>
			</section>

			<section id="main">
				<div class="inner">
					<header class="major special">
						<h2>Technologies</h2>
					</header>
					<p> 
						<b>Machine Learning Algorithm:</b>
						Neural Network
						<br/>
						<b>Frameworks:</b>
						TensorFlow with Keras
						<br/>
						<b>Front-End Web Framework:</b>
						React
						<br/>
						<b>Back-End Web Framework:</b>
						Flask
						<br/>
						<b>Version Control:</b> 
						We will use GitHub for version control. We will have master contain functional code, with each task in it's own branch. Commits need to have concise and descriptive titles.
						<br/>
						<b>Issue Tracking:</b>
						GitHub Issues for issue tracking.
					</p>
				</div>
			</section>

			<section id="main">
				<div class="inner">
					<header class="major special">
						<h2>Progress</h2>
					</header>
                    <p>
                    	<b>Project Completion:</b> <progress value = "100" max = "100"></progress> 100%
                    	<br/>
                    	<b>First Stage:</b> Creating Requirements <progress value = "100" max = "100"></progress> 100%
                    	<br/>
                    	<b>Third Stage:</b> Implementation <progress value = "100" max = "100"></progress> 100%
                    	<br/>
                    	<b>Final Stage:</b> Testing and Delivery <progress value = "100" max = "100"></progress> 100%
					</p>
				</div>
			</section>

			<section id="main">
				<div class="inner">
					<header class="major special">
						<h2>Codebase</h2>
					</header>
					<p> 
						Link to our GitHub Organization here: <a href="https://github.com/intelliChirp/">IntelliChirp Organization</a><br/><br/>
						Repositories in IntelliChirp Organization:<br/>
						<b><a href="https://github.com/intelliChirp/SNAW" target="_blank">SNAW</a></b>: Web Application<br/>
						<b><a href="https://github.com/intelliChirp/SNAW-Offline" target="_blank">SNAW-Offline</a></b>: Offline Standalone Application<br/>
						<b><a href="https://github.com/intelliChirp/Soundscape-Neural-Network" target="_blank">Soundscape-Neural-Network</a></b>: Neural Networks
					</p>
				</div>
			</section>

			<section id="main">
				<div style="text-align: center;">
					<h2>Demo</h2>
					Here are a couple screenshots from our demo.
					<h5> <br/>Uploading Audio for Analysis </h5>
					<img src="images/homepage.png" style="width:80%">
					<h5> <br/>Analyze the audio and give results </h5>
					<img src="images/analyzing.png" style="width:80%">
					<h5> <br/>Visualizing results from analysis (Spectrogram, Pie Charts, Acoustic Indices)</h5>
					<img src="images/visualization1.png" style="width:80%">
					<img src="images/visualization2.png" style="width:80%">
					<img src="images/visualization3.png" style="width:80%">
					<img src="images/visualization4.png" style="width:80%">
					<img src="images/export1.png" style="width:80%">
					<h5> <br/>Export classification as CSV file </h5>
					<img src="images/export2.png" style="width:80%">
				</div>
			</section>


		<!-- Footer -->
		<section id="footer">
			<div class="inner">
				2020 NAU Capstone Team IntelliChrip: Steven Enriquez, Josh Kruse, Michael Ewers, Zhenyu Lei
				<div class="copyright">
					&copy; Untitled Design: <a href="https://templated.co/">TEMPLATED</a>.
				</div>
			</div>
		</section>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
            <script src="assets/js/main.js"></script>

	</body>
</html>
